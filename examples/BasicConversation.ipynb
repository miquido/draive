{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic usage of draive with OpenAI\n",
    "\n",
    "Add OPENAI_API_KEY key to the .env file to allow access to OpenAI services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from draive import load_env\n",
    "\n",
    "load_env()  # loads OPENAI_API_KEY from .env file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import UTC, datetime\n",
    "\n",
    "from draive import tool\n",
    "\n",
    "\n",
    "# prepare a basic tool for getting current date and time\n",
    "@tool(description=\"UTC time and date now\")\n",
    "async def utc_datetime() -> str:\n",
    "    return datetime.now(UTC).strftime(\"%A %d %B, %Y, %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "OpenAIChatConfig.__init__() missing 8 required keyword-only arguments: 'temperature', 'top_p', 'frequency_penalty', 'max_tokens', 'seed', 'response_format', 'vision_details', and 'timeout'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdraive\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     LMM,\n\u001b[1;32m      3\u001b[0m     ConversationMessage,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     openai_lmm_invocation,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# initialize dependencies and configuration\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mnew(\n\u001b[1;32m     14\u001b[0m     dependencies\u001b[38;5;241m=\u001b[39m[OpenAIClient],  \u001b[38;5;66;03m# use OpenAI client\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     state\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     16\u001b[0m         LMM(invocation\u001b[38;5;241m=\u001b[39mopenai_lmm_invocation),  \u001b[38;5;66;03m# define used LMM\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m         \u001b[43mOpenAIChatConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-0125\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,  \u001b[38;5;66;03m# configure OpenAI model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     ],\n\u001b[1;32m     19\u001b[0m ):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# request conversation completion\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     response: ConversationMessage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m conversation_completion(  \u001b[38;5;66;03m# noqa: PLE1142\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;66;03m# provide a prompt instruction\u001b[39;00m\n\u001b[1;32m     23\u001b[0m         instruction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m         ),\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[0;31mTypeError\u001b[0m: OpenAIChatConfig.__init__() missing 8 required keyword-only arguments: 'temperature', 'top_p', 'frequency_penalty', 'max_tokens', 'seed', 'response_format', 'vision_details', and 'timeout'"
     ]
    }
   ],
   "source": [
    "from draive import (\n",
    "    LMM,\n",
    "    ConversationMessage,\n",
    "    OpenAIChatConfig,\n",
    "    OpenAIClient,\n",
    "    Toolbox,\n",
    "    conversation_completion,\n",
    "    ctx,\n",
    "    openai_lmm_invocation,\n",
    ")\n",
    "\n",
    "# initialize dependencies and configuration\n",
    "async with ctx.new(\n",
    "    dependencies=[OpenAIClient],  # use OpenAI client\n",
    "    state=[\n",
    "        LMM(invocation=openai_lmm_invocation),  # define used LMM\n",
    "        OpenAIChatConfig(model=\"gpt-3.5-turbo-0125\"),  # configure OpenAI model\n",
    "    ],\n",
    "):\n",
    "    # request conversation completion\n",
    "    response: ConversationMessage = await conversation_completion(  # noqa: PLE1142\n",
    "        # provide a prompt instruction\n",
    "        instruction=\"You are a helpful assistant.\",\n",
    "        # add user input\n",
    "        input=\"Hi! What is the time now?\",\n",
    "        # define tools available to the model\n",
    "        tools=Toolbox(\n",
    "            utc_datetime,\n",
    "        ),\n",
    "    )\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
